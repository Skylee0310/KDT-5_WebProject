import cgi, sys, codecs
import datetime
import torch
import torch.nn as nn
from sklearn.metrics import r2_score, mean_squared_error
import pickle


sys.stdout=codecs.getwriter(encoding='utf-8')(sys.stdout.detach())

# ì›¹ í˜ì´ì§€ì˜ form íƒœê·¸ ë‚´ì˜ input íƒœê·¸ ì…ë ¥ê°’ ê°€ì ¸ì™€ì„œ
# ì €ì¥í•˜ê³  ìˆëŠ” ì¸ìŠ¤í„´ìŠ¤
form = cgi.FieldStorage()


# ì„ íƒí•œ ì˜µì…˜ ê°’ì„ ê°€ì ¸ì˜¤ê¸°
selected_option = form.getvalue('model')


# ëª¨ë¸ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
class ScoreRegression(nn.Module):
    def __init__(self,
                 n_vocab,
                 hidden_dim,
                 embedding_dim,
                 n_layers,
                 dropout=0.5,
                 bidirectional=True,
                 model_type='lstm'):
        super(ScoreRegression, self).__init__()
        
        self.embedding = nn.Embedding(
            num_embeddings=n_vocab,
            embedding_dim=embedding_dim,
            padding_idx=0)
        
        if model_type == 'rnn':
            self.model = nn.RNN(
                input_size=embedding_dim,
                hidden_size=hidden_dim,
                num_layers=n_layers,
                bidirectional=bidirectional,
                dropout=dropout,
                batch_first=True,
            )
        elif model_type == 'lstm':
            self.model = nn.LSTM(
                input_size=embedding_dim,
                hidden_size=hidden_dim,
                num_layers=n_layers,
                bidirectional=bidirectional,
                dropout=dropout,
                batch_first=True,
            )
        if bidirectional:
            self.regression = nn.Linear(hidden_dim*2, 1)
        else:
            self.regression = nn.Linear(hidden_dim,1)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, inputs):
        embeddings = self.embedding(inputs)
        output, _ = self.model(embeddings)
        last_output = output[:, -1, :]
        last_output = self.dropout(last_output)
        logits = self.regression(last_output)
        
        return logits


ScoreRegression_rnn = torch.load('./model/regression_rnn.pth', map_location=torch.device('cpu'))
ScoreRegression_rnn2 = torch.load('./model/regression_rnn2.pth', map_location=torch.device('cpu'))
ScoreRegression_lstm = torch.load('./model/regression_lstm.pth', map_location=torch.device('cpu'))
ScoreRegression_lstm2 = torch.load('./model/regression_lstm2.pth', map_location=torch.device('cpu'))




# ë‹¨ì–´ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°
with open('./vocab1.pkl', 'rb') as f:
    vocab1 = pickle.load(f)


# ì…ë ¥ëœ ìŠ¤í† ë¦¬ í† í°í™” ëª¨ë“ˆ ë‹¤ìš´
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# NLTKì˜ ë¶ˆìš©ì–´ ë‹¤ìš´ë¡œë“œ
nltk.download('stopwords')
nltk.download('punkt')

# ì˜ì–´ì˜ ë¶ˆìš©ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
stop_words = set(stopwords.words('english'))

# í† í°í™” í•¨ìˆ˜ ìƒì„±
def text_pipeline(text):
    tokenList = word_tokenize(text)
    return vocab1(tokenList)

# íŒ¨ë”©í•¨ìˆ˜
def pad_sequences(sentences, maxlen, pad, start='R'):
    result = []
    for sen in sentences:
        sen = sen[:maxlen] if start == 'R' else sen[:maxlen*(-1)]
        padd_sen = sen + [pad] * (maxlen-len(sen)) if start == 'R' else [pad] * (maxlen-len(sen)) + sen
        result.append(padd_sen)
    
    return result


# ì¸ì½”ë”©& ë””ì½”ë”© ì¸ë±ì‹±
### ì¸ì½”ë”© : ë¬¸ì >>>> ìˆ«ìë¡œ ë³€í™˜
token_to_id ={ label : id  for label, id in vocab1.get_stoi().items()}

### ë””ì½”ë”© : ìˆ«ì >>>> ë¬¸ìë¡œ ë³€í™˜
id_to_token ={ id : label  for label, id in vocab1.get_stoi().items()}



# data_ids = [[vocab1.get_stoi().get(token,1) for token in text] for text in tokens]




# ì˜ˆì¸¡í•¨ìˆ˜ ìƒì„±
def predict(model, text, text_pipeline):
    with torch.no_grad():
        # í† í°í™” => ì •ìˆ˜ë³€í™˜ => í…ì„œ
        text=pad_sequences([text_pipeline(text)],30, 0)
        text = torch.tensor(text)
        logits = model(text)
        return logits.item()



if selected_option == 'rnn':
    model = ScoreRegression_rnn
elif selected_option == 'lstm':
    model = ScoreRegression_lstm
elif selected_option == 'rnn2':
    model = ScoreRegression_lstm
elif selected_option == 'lstm2':
    model = ScoreRegression_lstm


# í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
text = form.getvalue('story')



result_score = predict(model,text,text_pipeline)








# ì›¹ì—ì„œ ë½‘ì•„ ë‚´ê¸°ì— ì´ ê³¼ì •ì´ í•„ìˆ˜
print("Content-Type: text/html; charset=utf-8")
print()
# print("<TITLE>ìŠ¤í† ë¦¬ì ìˆ˜ íšŒê·€ë¶„ì„ ê²°ê³¼</TITLE>")
# print("<H1>ìŠ¤í† ë¦¬ì ìˆ˜ íšŒê·€ë¶„ì„ ê²°ê³¼</H1>")
# print(f"<h3>ì„ íƒí•œ ëª¨ë¸:</h3>")
# print(f'<p>{selected_option}</p><br>')
# print(f"<p>ì˜ˆìƒ ì ìˆ˜ : {round(result_score,2)}</p><br>")

print(f'''<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ì¤„ê±°ë¦¬ë¡œ ì˜í™”ì ìˆ˜ ë½‘ì•„ë‚´ê¸°</title>
    <link href ='../css/model.css' rel = "stylesheet">
</head>
<body>
    <center>
    <h2 style = "font-size: 30px;">ğŸ’– ì˜í™” ì¤„ê±°ë¦¬ë¡œ í‰ì  ë¶„ë¥˜í•˜ê¸° ğŸ’–</h2>
    <form method="post" action ="/cgi-bin/send_story_data.py" enctype="multipart/form-data">
        <fieldset>
            <p>
                <h3>ì„ íƒí•œ ëª¨ë¸:</h3>
                <h3>{selected_option}</h3><br>
                <b>ì˜ˆìƒ ì˜í™” ì ìˆ˜ : {round(result_score,2)}</b><br>
            </p>

            <p>
                <label for="model">ì‚¬ìš© ëª¨ë¸ ì„ íƒ : </label>
                <select id="model" name="model">
                    <option value="rnn">rnnëª¨ë¸ ver1000</option>
                    <option value="rnn2">rnnëª¨ë¸ ver4000</option>
                    <option value="lstm">lstmëª¨ë¸ ver1000</option>
                    <option value="lstm2">lstmëª¨ë¸ ver4000</option>
                </select>
            </p>
        </fieldset>
        
    </form>
    </center>
</body>
</html>''')